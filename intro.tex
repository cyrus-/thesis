% !TEX root = omar-thesis.tex
\chapter{Introduction}\label{chap:intro}
\begin{quote}\textit{The recent development of programming languages suggests that the simul\-taneous achievement of simplicity 
and generality in language design is a serious unsolved 
problem.}\begin{flushright}--- John Reynolds (1970) \cite{Reynolds70}\end{flushright}
\end{quote}
\section{Motivation}\label{sec:intro-motivation}

%``Full-scale' typed functional programming languages like Standard ML (SML) \cite{mthm97-for-dart,harper1997programming}, OCaml \cite{ocaml-manual} and Haskell \cite{jones2003haskell} are members of a conceptual lineage rooted in the typed lambda calculus \cite{Reynolds94anintroduction}. 

Programming languages come in many sizes. Small languages -- i.e. ``formal {calculi}'' -- allow language designers to  study the mathematical properties of language primitives of interest in isolation. These studies then inform the design of ``full-scale'' 
%\footnote{Throughout this work, words and phrases that should be read as having an intuitive or informal meaning, rather than a strict mathematical meaning, will be introduced with quotation marks.} 
 languages, which combine several such primitives, or generalizations thereof.

Because small-scale languages are of interest mainly as objects of mathematical study, their designers often choose to specify only the abstract syntax of their primitives (or, when typesetting documents, stylized representations thereof). Full-scale languages, on the other hand, are both interesting objects of mathematical study and, ideally, useful for write large programs, so they  typically also specify a more ``programmer-friendly'' textual concrete syntax that features various \emph{derived syntactic forms}, i.e. forms defined by a context-independent ``desugaring'' to the set of base forms, that decrease the syntactic cost of certain common idioms. 
For example, Standard ML (SML) \cite{mthm97-for-dart,harper1997programming}, OCaml \cite{ocaml-manual} and Haskell \cite{jones2003haskell}   build in 
%record types, generalizing the nullary and binary product types that suffice in simpler calculi, because labeled components are cognitively useful to human programmers. Similarly, these languages all build in 
derived forms that decrease the syntactic cost of working with lists. In these languages, the form \lstinline{[1, 2, 3, 4, 5]} desugars to: 
\begin{lstlisting}[numbers=none]
Cons(1, Cons(2, Cons(3, Cons(4, Cons(5, Nil)))))
\end{lstlisting}

The hope amongst many language designers is that a limited number of derived forms like these will suffice to produce a ``general-purpose'' programming language, i.e. one that satisfies programmers working in a wide variety of application domains. Unfortunately, a stable language design that fully achieves this ideal has yet to emerge, as evidenced by the diverse array of \emph{syntactic dialects} -- dialects that introduce only new derived forms -- that continue to proliferate around all major contemporary languages. For example, Ur/Web is a syntactic dialect of Ur (an ML-like full-scale language \cite{conf/pldi/Chlipala10}) that builds in derived forms for SQL queries, HTML elements and other datatypes used in the domain of web programming \cite{conf/popl/Chlipala15}. %Syntactic cost is often assessed qualitatively \cite{green1996usability}, though quantitative metrics can be defined. 
We will consider a large number of other examples of syntactic dialects in Sec. \ref{sec:motivating-examples}. 
Tools like Camlp4 \cite{ocaml-manual}, Sugar* \cite{erdweg2011sugarj,erdweg2013framework} and Racket's preprocessor \cite{Flatt:2012:CLR:2063176.2063195}, which we will discuss in Sec. \ref{sec:existing-approaches}, have decreased the engineering costs of constructing syntactic dialects, further contributing to their proliferation. 

%In fact, tools that aid in the construction of so-called  ``domain-specific'' language dialects (DSLs)\footnote{In some parts of the literature, such dialects are called ``external DSLs'', to distinguish them from  ``internal'' or ``embedded DSLs'', which are actually  library interfaces that only ``resemble'' distinct dialects \cite{fowler2010domain}.} seem only to be becoming more prominent over time. 

%\subsection{Why are there so many language dialects?}
%{This calls for an investigation}: why is it that programmers and researchers are still so often unable to satisfyingly express the constructs that they seek in libraries, as modes of use of the ``general-purpose'' primitives already available in major languages today, and instead see a need for new language dialects?

%Perhaps the most common sort of dialect is the \emph{syntactic dialect} -- a dialect that introduces only new derived syntactic forms, motivated by a desire to decrease the {syntactic cost} of working with one or more library constructs of interest. 
%Put another way, syntactic dialects can be specified by a context-independent expansion to the existing language that they are based on. 
%For example, Ur/Web is a syntactic dialect of Ur (a language that itself descends from ML \cite{conf/pldi/Chlipala10}) that builds in derived forms for SQL queries, HTML elements and other datatypes used in the domain of web programming \cite{conf/popl/Chlipala15}. %Syntactic cost is often assessed qualitatively \cite{green1996usability}, though quantitative metrics can be defined. 
%This is not an isolated example -- we will consider a number of additional types of data that similarly stand to benefit from the availability of specialized derived forms in Sec. \ref{sec:motivating-examples}. 
%Tools like Camlp4 \cite{ocaml-manual}, Sugar* \cite{erdweg2011sugarj,erdweg2013framework} and Racket \cite{Flatt:2012:CLR:2063176.2063195}, which we will discuss in Sec. \ref{sec:existing-approaches}, have lowered the engineering costs of constructing syntactic dialects in such situations, further contributing to their proliferation. 

%More advanced dialects introduce new type structure, going beyond what is possible with only new derived forms. As a simple example, the static and dynamic semantics of records cannot be expressed by context-independent expansion to a language with only nullary and binary products. Various languages have explored ``record-like'' primitives that go further, supporting functional update operators, width and depth coercions (sometimes implicit)%\cite{Cardelli:1984:SMI:1096.1098}
%, methods, prototypic dispatch and other such ``semantic embellishments'' that in turn cannot be expressed by context-independent expansion to a language with only standard record types (we will detail an  example in Sec. \ref{sec:metamodules-motivating-examples}). OCaml primitively builds in the type structure of polymorphic variants, open datatypes and  operations that use format strings like $\mathtt{sprintf}$ \cite{ocaml-manual}. ReactiveML builds in primitives for functional reactive programming \cite{mandel2005reactiveml}. ML5 builds in high-level primitives for distributed programming based on a modal lambda calculus \cite{Murphy:2007:TDP:1793574.1793585}. Manticore \cite{conf/popl/FluetRRSX07} and AliceML  \cite{AliceLookingGlass} build in parallel programming primitives with a more elaborate type structure than is found in simpler accounts of parallelism. 
%MLj builds in the type structure of the Java object system (motivated by a desire to interface safely and naturally with Java libraries) \cite{Benton:1999:IWW:317636.317791}. Other dialects do the same for other foreign languages, e.g. Furr and Foster describe a dialect of OCaml that builds in the type structure of C \cite{Furr:2005:CTS:1065010.1065019}. Tools like proof assistants and logical frameworks are used to specify and reason metatheoretically about dialects like these, and tools like compiler generators and language frameworks \cite{erdweg2013state} lower their implementation cost, again contributing to their proliferation. 

\subsection{Dialects Considered Harmful}
% express record types as syntactic sugar over the simply-typed lambda calculus with  binary product types.\footnote{Pairs can of course be expressed as syntactic sugar atop records, though one could argue that using binary products as the more primitive concept is simpler.} The static semantics need to be extended with new type and term operators. However, the simplest way to express the dynamic semantics of the newly introduced term operators is by translation to nested binary products, so we can leave the operational semantics alone. \todo{fill this out} %For example, there are dozens of constructs that go by the name of ``records'' in various languages, each defined by a slightly different collection of primitive operations. \todo{examples} %, encouraged  historically  by the availability of tools like compiler generators and,  more recently, language workbenches \cite{workbenches} and DSL frameworks \cite{dsl}. Unfortunately, taking this approach makes it substantially more difficult for clients to import high-level abstractions orthogonally. 
% test 
Some  view this proliferation of dialects as harmless or even as desirable, arguing that programmers can simply choose the right dialect for the job at hand \cite{journals/stp/Ward94}. However, this ``dialect-oriented'' approach is, in an important sense, anti-modular: programmers cannot always ``combine'' different dialects when they want to use the primitives that they feature together within a single program. For example, a programmer might have access to a dialect featuring HTML syntax and to a dialect featuring regular expression syntax, but it is not always straightforward to, from these, construct a dialect featuring both. Both HTML and regular expression syntax might be useful when constructing, for example, a web-based bioinformatics tool. 

In some cases, constructing the desired ``combined dialect'' is difficult simply because the constituent dialects are specified using different formalisms. In other cases, the constituent dialects may be specified using a formalism that does not operationalize the notion of dialect combination (e.g. Racket's preprocessor \cite{Flatt:2012:CLR:2063176.2063195}). But even if we restrict our interest to dialects specified using a formalism that does operationalize some notion of dialect combination (or, equivalently, one that allows programmers to combine ``dialect fragments''), there may still be a problem: the formalism may not guarantee that the combined dialect will conserve important properties that can be established about the dialects in isolation. %In other words, any putative ``combined language'' must formally be considered a  distinct system for which one must derive essentially all metatheorems of interest anew, guided only informally by those derived for the dialects individually. %There is no well-defined mechanism for constructing such a ``combined language'' in general. 
For example, consider two syntactic dialects specified using Camlp4, one specifying derived syntax for finite mappings, the other specifying overlapping syntax for \emph{ordered} finite mappings. Though each dialect has a deterministic grammar, when these grammars are na\"ively  combined, syntactic ambiguities will arise. We are aware of only one formalism that guarantees that determinism is conserved when syntactic dialects are combined \cite{conf/pldi/SchwerdfegerW09}, but it has limited expressive power, as we will discuss in Sec. \ref{sec:direct-syntax-extension}.
%It is thus infeasible to simply allow different contributors to a software system to choose their own favorite dialect for each component they are responsible for. 
%It it clear that dialects are better rhetorical devices than practical engineering artifacts. 

%Due to this paucity of modular reasoning principles, the ``dialect-oriented'' approach is problematic for software development ``in the large''. %Large software projects and software ecosystems must pick a single language that does provide powerful modular reasoning principles and, to benefit from them, stay inside it.

\subsection{Large Languages Considered Harmful}
Dialects do sometimes have a less direct influence on large-scale software development: they can help convince the designers in control of comparatively popular languages, like OCaml and Scala, to include some variant of the primitives that they feature into backwards-compatible language revisions. %These decisions are increasingly influenced by community processes, e.g. the Scala Improvement Process.  %This approach concentrates power as well as responsibility over maintaining metatheoretic guarantees in the hands of a small group of language designers, though increasingly influenced by various community processes (e.g. the Scala Improvement Process). 
%Dialects thus serve the role of rhetorical vehicles for new ideas, rather than direct artifacts. 
%Over time, accepting such extensions has caused these languages to balloon in size. 
This \emph{ad hoc} approach is unsustainable, for three main reasons. First, as we will demonstrate in Sec. \ref{sec:motivating-examples}, there are simply too  many potentially useful such primitives, and many of these capture idioms common only in relatively narrow application domains. It is unreasonable to expect language designers to be able to evaluate all of these use cases in a timely and informed manner. Second, primitives introduced earlier in a language's lifespan can end up monopolizing finite ``syntactic resources'', forcing subsequent primitives to use ever more esoteric forms. And third, primitives that prove after some time to be flawed in some way cannot be removed or modified without breaking backwards compatibility. For these reasons, language designers are justifiably reticent to add new primitives to major languages.%Because there is often no empirical data about how useful a construct is in practice until it is available in a major language, decisions about which constructs to include are often informed only by intuition (and are thus)
%Recalling the words of  Reynolds, which are clearly as relevant today as they were almost half a century ago \cite{Reynolds70}: %This approach is antithetical to the ideal of a truly \emph{general-purpose language} described at the beginning of this section.
%\newpage

\subsection{Toward More General Primitives}
This leaves two possible paths forward. One is to simply eschew ``niche'' primitives and settle on the existing designs, which might be considered to sit at a ``sweet spot'' in the overall language design space (accepting that in some circumstances, this leads to  high syntactic cost). 
The other path forward is to search for a small number of highly general primitives that allow us degrade many of the constructs that are built primitively into languages and their dialects today instead to modular library constructs. 
Encouragingly, primitives of this sort do occasionally arise. For example, a recent revision of OCaml added support for  generalized algebraic data types (GADTs), based on research on guarded recursive datatype constructors \cite{XiCheChe03}. Using GADTs, OCaml was able to move some of the \emph{ad hoc} machinery for typechecking operations that use format strings, like \li{sprintf}, out of the language and into a library. Syntactic machinery related to \li{sprintf}, however, remains built in. 

%Similarly, it recently introduced ``open datatypes'', which subsume its previous more specialized exception type, and captures many use cases for .

%Viewed ``dually'', one might equivalently ask for a language that builds in a core that is as small as possible, but provides expressive power comparable to languages with much larger cores. This is our goal in the work being proposed

%Similarly, it recently introduced ``open datatypes'', which subsume its previous more specialized exception type, and captures many use cases for .

%Viewed ``dually'', one might equivalently ask for a language that builds in a core that is as small as possible, but provides expressive power comparable to languages with much larger cores. This is our goal in the work being proposed. 

%\vspace{-10px}
\section{Overview of Contributions}\label{sec:contributions}
%%Our broad aim in the work being proposed is to introduce primitive language mechanisms that give library providers the ability to  express new syntactic expansions as well as new types and operators in a safe and modularly composable manner. 
Our aim in this work is to introduce primitive language constructs that reduce the need for syntactic dialects and \emph{ad hoc} derived syntactic forms. In particular, we introduce the following primitives:
% By supporting the primitives that we introduce, 1) VerseML will be smaller than comparable languages like ML and Scala, and 2) dialect formation will be less frequently necessary. In other words, these primitives reduce the need for many others:%This eliminates the needs to build in fewer \emph{ad hoc} constructs and dialects are less frequently necessary. %thereby reducing the need for language dialects and revisions. 

%VerseML features a module system taken directly from SML. Unlike SML, the VerseML core language is split into a \emph{typed external language} (EL) specified by {type-directed translation} to a minimal \emph{typed internal language} (IL). 
\begin{enumerate}
\item \textbf{Typed syntax macros}, or \textbf{TSMs}. TSMs are applied like functions to \emph{generalized literal forms} to programmatically control their  parsing and expansion. This occurs statically (i.e. simultaneously with typing). We  introduce TSMs first for a simple language of expressions and types in Chapter \ref{chap:tsms}, then add support for pattern matching  in Chapter \ref{sec:pattern-tsms} and type and module parameters in Chapter \ref{sec:tsms-parameterized}.
\item \textbf{Type-specific languages}, or \textbf{TSLs}. TSLs, described in Chapter \ref{chap:tsls}, further reduce syntactic cost by allowing library providers to designate a privileged TSM for each type that they introduce. Library clients can then rely on local type inference to invoke that TSM and apply its parameters implicitly. TSLs can reduce the syntactic cost of an idiom to very nearly the same extent that a special-purpose dialect can, while avoiding the problems described above.
%\item \textbf{Metamodules}, introduced in Sec. \ref{sec:metamodules}, reduce the need to primitively build in the type structure of constructs like records (and variants thereof),  labeled sums and other interesting constructs that we will introduce later by giving library providers programmatic ``hooks'' directly into the semantics, which are specified as a \emph{type-directed translation semantics} targeting a small \emph{typed internal language} (introduced in Sec. \ref{sec:VerseML}). %For example, a library provider can implement the type structure of records with a metamodule that:
%\begin{enumerate}
%\item introduces a type constructor, \lstinline{record}, parameterized by finite mappings from labels to types, and defines, programmatically, a translation to unary and binary product types (which are built in to the internal language); and 
%\item introduces operators used to work with records, minimally record introduction and elimination (but perhaps also various functional update operators), and directly implements the logic governing their typechecking and translation to the IL (which builds in only nullary and binary products). 
%\end{enumerate}
%We will see direct analogies between ML-style modules (which our mechanisms also support) and metamodules later.
\end{enumerate} 

As vehicles for this work, we will specify a small-scale typed lambda calculus in each of the chapters just mentioned, each building upon the previous one. For the sake of examples, we will also describe (but not formally specify) a full-scale functional language called VerseML.\footnote{We distinguish VerseML from Wyvern, which is the language described in our prior publications about some of the work that we will describe, because Wyvern is a group effort evolving independently.} VerseML is, as its name suggests, a dialect of ML. It diverges from other dialects of ML that have a similar underlying type structure, like Standard ML and OCaml, in that it uses a local type inference scheme \cite{Pierce:2000:LTI:345099.345100} (like, for example, Scala \cite{OdeZenZen01}) for reasons that have to do with the mechanisms described in Chapter \ref{chap:tsls}. The reason we will not follow Standard ML \cite{mthm97-for-dart} in giving a complete formal specification of VerseML in this work is both to emphasize that the primitives we introduce are fairly insensitive to the details of the underlying type structure of the language (so TSMs can be considered for inclusion in a variety of languages, not only dialects of ML), and to avoid distracting the reader (and the author) with specifications of primitives that are already well-understood in the literature and that are orthogonal to those that are the focus of this work. %We anticipate that future full-scale language specifications will be able to combine the ideas  in the proposed work without trouble. %The purpose of the work being proposed is to serve as a reference for those interested in the new constructs we introduce, not to serve as a language specification. 
%We will give a brief overview of these languages are organized in Sec. \ref{sec:VerseML}.

%TSMs, like other macro systems, perform \emph{static code generation} (also sometimes called \emph{static} or \emph{compile-time metaprogramming}), meaning that the relevant rules in the static semantics of the language call for the evaluation of \emph{static functions} that generate term encodings. Static functions are functions that are evaluated statically, i.e. during typing. %Library providers write these static functions using the VerseML \emph{static language} (SL).  
%Maintaining a separation between the static (or ``compile-time'') phase and the dynamic (or ``run-time'') phase is an important facet of VerseML's design. % static code generation. %We will  also introduce a simple variant of each of these primitives that leverages VerseML's support for local type inference to further reduce syntactic cost in certain common situations. 


The main challenge will come in maintaining the following:
\begin{itemize}
\item a \emph{type discipline}, meaning that the language must be type safe, and that programmers examining a well-typed expression must be able to determine its type without examining its expansion; 
\item a \emph{hygienic binding discipline}, meaning that the expansion logic must not be permitted to make ``hidden assumptions'' about the names of variables at macro application sites, nor  introduce ``hidden bindings'' into other terms; and 
\item \emph{modular reasoning principles}, meaning that library providers must have the ability to reason about the syntax that they have defined in isolation, and clients must be able to use macros safely in any combination, without the possibility of conflict.\footnote{This is not quite true --  name clashes of the usual sort can arise. We will tacitly assume that in practice, they can be avoided extrinsically, e.g. by using a URI-based naming scheme as in the Java ecosystem.} 
\end{itemize}
\noindent
We will, of course, make these notions more technically precise as we continue.

\subsection*{Thesis Statement}
In summary, this work defends the following statement:

\begin{quote}
A functional programming language can give library providers the ability to %meta\-pro\-gram\-matic\-ally 
express new syntactic expansions while maintaining a type discipline, a hygienic binding discipline and modular reasoning principles. %These  primitives are  expressive enough to subsume the need for a variety of primitives that are, or would need to be, built in to comparable contemporary languages.
\end{quote}
\section{Disclaimers}
Before we continue, it may be prudent to explicitly acknowledge that completely eliminating the need for dialects would indeed be asking for too much: certain language design decisions are fundamentally incompatible with others or require coordination across a language design. We aim only to decrease the need for syntactic dialects in this work. We will not consider situations that require modifications to the underlying type structure of a language (though this is a rich avenue for future work). % out a larger design space within a single language, VerseML.%a subset of constructs that can be specified by a semantics of a certain ``shape'' specified by VerseML (we will make this more specific later). %There is nothing ``universal'' about VerseML.

It may also be useful to explicitly acknowledge that library providers could leverage the primitives we introduce   to define constructs that are in ``poor taste''. We  expect that in practice, VerseML will come with a standard library defining an expertly curated collection of standard constructs, as well as guidelines for advanced users regarding when it would be sensible to use the mechanisms we introduce (following the example of languages that support operator overloading or type classes \cite{Hall:1996:TCH:227699.227700}, which also have some potential for ``abuse'' or ``overuse''). %For most programmers, using VerseML should not be substantially different from using a language like ML or one of its dialects.%The vast majority of programmers should not use the primitives that we introduce directly.

%Finally, VerseML is not designed as a dependently-typed language like Coq, Agda or Idris. %because these languages do not maintain a phase separation between ``compile-time'' and ``run-time.'' This phase separation is useful for programming tasks (where one would like to be able to discover errors before running a program, particularly programs that may have an effect) but less so for theorem proving tasks (where it is mainly the fact that a pure expression is well-typed that is of interest, by the propositions-as-types principle). 
